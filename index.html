<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>NYC Subway Data Analysis by Inquisitive-Geek</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">NYC Subway Data Analysis</h1>
      <h2 class="project-tagline">Analysis and Regression modeling of NYC Subway dataset to check affect of rain on Subway ridership</h2>
      <a href="https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset" class="btn">View on GitHub</a>
      <a href="https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>

<p>In this project, we look at the NYC Subway data and figure out if more people ride the subway when it is raining versus when it is not raining. We will wrangle the NYC subway data, use statistical methods and data visualization to draw an interesting conclusion about the subway dataset that we've analyzed.</p>

<h2>
<a id="problems-encountered-in-the-map" class="anchor" href="#problems-encountered-in-the-map" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problems Encountered in the Map</h2>

<p>After initially downloading a small sample size of the Raleigh data and running it against a provisional data.py file, I noticed three main problems with the data, which I will discuss in the following order:</p>

<ul>
<li>
<em>Multiple streets for a node:</em> A university like NCSU has multiple streets in it. But the street keys aren’t of the form “addr:street”. In such cases, the data is still cleaned for the streets but they are not added to an address dictionary value. Instead, the keys are kept as is.</li>
<li>
<em>Relation nodes:</em> There are some nodes who have element names as ‘Relation’. They are handled in a similar way as ways and nodes.</li>
<li>
<em>Postal codes:</em> There are a lot of postal codes which don’t pertain to Raleigh, NC. Some investigation is done around it to find out the root cause.</li>
</ul>

<h2>
<a id="data-overview" class="anchor" href="#data-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Overview</h2>

<p>This section contains basic statistics about the dataset and the MongoDB queries used to gather them.</p>

<h2>
<a id="additional-ideas" class="anchor" href="#additional-ideas" aria-hidden="true"><span class="octicon octicon-link"></span></a>Additional Ideas</h2>

<h3>
<a id="contributor-statistics-and-gamification-suggestion" class="anchor" href="#contributor-statistics-and-gamification-suggestion" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Contributor statistics and gamification suggestion</strong>
</h3>

<p>Few users contribute to the most data which suggests automated entry of some admin. Here are some statistics:</p>

<ul>
<li>Top user contribution percentage (“jumbanho”) – 76.82%</li>
<li>Top user contribution percentage (“jumbanho”) – 76.82%</li>
</ul>

<p>It is clear that the contribution of the top 10 users is too high as compared to the total number of users (724). If some incentives are given to the users to contribute more, it will help spur the data entry process and will also provide more quality to the data. </p>

<h3>
<a id="additional-data-exploration-using-mongodb-queries" class="anchor" href="#additional-data-exploration-using-mongodb-queries" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Additional data exploration using MongoDB queries</strong>
</h3>

<h2>
<a id="linear-regression" class="anchor" href="#linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Linear Regression</h2>

<p>OLS using Statsmodels library was the approach used to perform linear regression. Gradient descent was not used as OLS is more accurate. Rain and Hour were the features used apart from the dummy variables which can be seen from the code below.</p>

<pre><code>import numpy as np
import pandas
import statsmodels.api as sm

def linear_regression(features, values):
    """
    Perform linear regression given a data set with an arbitrary number of features.
    """

    features = sm.add_constant(features,prepend=True)
    model = sm.OLS(values,features).fit()
    print model.summary()
    params = model.params
    intercept = params[0]
    params = params[1:]
    return intercept, params

def predictions(dataframe):
    features = dataframe[['rain', 'Hour']]
    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')
    features = features.join(dummy_units[['unit_R170','unit_R022','unit_R179','unit_R029','unit_R012',
                            'unit_R046','unit_R023','unit_R047','unit_R293','unit_R055','unit_R084','unit_R011',
                            'unit_R178','unit_R452','unit_R001','unit_R108',
                            'unit_R010','unit_R195','unit_R021','unit_R102','unit_R018','unit_R033',
                            'unit_R175','unit_R177','unit_R051','unit_R138','unit_R017','unit_R057',
                            'unit_R168','unit_R080','unit_R050','unit_R127','unit_R025',
                            'unit_R141','unit_R163','unit_R044','unit_R019','unit_R031','unit_R248','unit_R032',
                            'unit_R083','unit_R461','unit_R240','unit_R235','unit_R208','unit_R014','unit_R053',
                            'unit_R020','unit_R142','unit_R081','unit_R028','unit_R222','unit_R131','unit_R105',
                            'unit_R113','unit_R144','unit_R167','unit_R079','unit_R463','unit_R035',
                            'unit_R132','unit_R176','unit_R300','unit_R158','unit_R164','unit_R097',
                            'unit_R101','unit_R116','unit_R027','unit_R110','unit_R201','unit_R160','unit_R041'
                            ]])

    # Values
    values = dataframe['ENTRIESn_hourly']

    # Perform linear regression
    intercept, params = linear_regression(features, values)

    predictions = intercept + np.dot(features, params)
    return predictions
</code></pre>

<h3>
<a id="choice-of-predictors-explained" class="anchor" href="#choice-of-predictors-explained" aria-hidden="true"><span class="octicon octicon-link"></span></a>Choice of Predictors Explained</h3>

<ul>
<li>‘rain’ is the first variable that comes to mind to decide whether people might use the subway or not. If it rains, then people might decide to use the subway. Also, ‘Hour’ of the day is another variable that helps in predicting usage of subway as people would use the subway more often in the mornings and the evenings as compared to late night or during the afternoon. All the dummy variables were included as they categorize the data and hence would help in identification. </li>
<li>To filter out the dummy variables, I ran a full model with all the dummy variables. The resulting model summary gave the t-values and p-values of the dummy variables. Inclusion of dummy variables with higher t-values improved the r-squared significantly. I sorted the variables in descending order of t-values and included dummy variables in the model till the r-squared value crossed the threshold mentioned of 0.4.</li>
</ul>

<h3>
<a id="non-dummy-coefficient-values-and-r2" class="anchor" href="#non-dummy-coefficient-values-and-r2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Non-dummy coefficient values and R^2</h3>

<p>_Coefficients of the non-dummy variables: _
‘const’: -18.9345
‘rain’: 62.6158
‘hour’: 59.1683</p>

<p><em>R^2 value of 0.401</em> means that the model explained 40.1% of the data fit the regression model line. This linear model to predict ridership is not appropriate for this dataset, given the R^2 value. It could be that some variables given in the dataset which could increase the R^2 value have not been identified. There is also a chance that some important variable has not been captured during data collection too.</p>

<h2>
<a id="visualizations" class="anchor" href="#visualizations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualizations</h2>

<p>A histogram of the hourly number of entries is plotted when there is rain and when there is not. The histograms are not normally distributed and have their peaks near 0. </p>

<pre><code>    df = turnstile_weather.groupby('TIMEn')
    dfSum = df['ENTRIESn_hourly'].sum()

    TIMEn = []
    ENTRIESn_hourlySum = []
    for key, value in dfSum.iteritems():
        TIMEn.append(key)
        ENTRIESn_hourlySum.append(value)
    ENTRIESn_hourlySum = np.log(ENTRIESn_hourlySum)    
    ENTRIESn_hourlySum = ENTRIESn_hourlySum.astype(int)
    dfPlot = DataFrame({'TIMEn':Series(TIMEn),'ENTRIESn_hourlySum':Series(ENTRIESn_hourlySum)})    
    #Filtering out the -inf values
    dfPlot = dfPlot[dfPlot['ENTRIESn_hourlySum'] &gt; 0]  
    #Getting the highest ENTRIESn_hour sum values 
    dfPlot = dfPlot[dfPlot['ENTRIESn_hourlySum'] &gt; (3*np.mean(dfPlot['ENTRIESn_hourlySum']))]    
    plot = ggplot(dfPlot,aes('TIMEn','ENTRIESn_hourlySum')) + geom_bar(stat="bar") + \
            ggtitle('Highest entry counts with times during the day') + xlab('Times in Day') + ylab('Log of Hourly Entries') 
    return plot
</code></pre>

<p><img src="https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset/blob/master/Images/Histogram.png?raw=true" alt="Histogram of subway entry frequency v/s times"></p>

<p>The below graph shows the plot of the mean pressure variation versus dates. It shows how the mean pressure variation varies on different days. </p>

<pre><code>    pandas.options.mode.chained_assignment = None  # default='warn'
    turnstile_weather.iscopy = False
    turnstile_weather.loc[:,('DATEn')] = pandas.to_datetime(turnstile_weather.loc[:,('DATEn')], format="%Y-%m-%d")
    df = turnstile_weather.groupby('DATEn')
    index = [gp_keys[0] for gp_keys in df.groups.values()]
    unique_df = turnstile_weather.reindex(index).sort('DATEn')   
    plot = ggplot(unique_df, aes(x='DATEn', y='meanpressurei')) + geom_line(color = 'red') + \
    ggtitle('Mean Pressure variation') + xlab('Date') + ylab('Mean Pressure') + scale_x_date(labels = date_format("%Y-%m-%d"))
    return plot
</code></pre>

<p><img src="https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset/blob/master/Images/Mean_Pressure_Vs_Date.png?raw=true" alt="Mean Pressure Variation v/s Date"></p>

<h2>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

<p>More people ride the NYC subway when it rains as compared to when it does not. The low two-sided p-value of 0.0498 indicates that the null hypothesis that the mean subway number of hourly entries with rain is equal to that without rain is rejected. The linear model indicates that rain is an important variable in deciding the number of hourly entries. The positive coefficient value of 63.64 for variable ‘rain’ shows that subway ridership increases by 63.64 on average when it rains.</p>

<h2>
<a id="reflection-on-shortcomings" class="anchor" href="#reflection-on-shortcomings" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reflection on Shortcomings</h2>

<p>The shortcomings of the methods used are as follows:</p>

<ul>
<li>The data is not captured for all the hourly intervals for each of the unit types indicating that the data is not complete. This causes a hindrance in building reliable models for our analysis.</li>
<li>The linear regression model has too many dummy variables being used. Ideally, the number of variables should be lesser in a dataset. The issue is that removing a few of the dummy variables caused a reduction in the R-squared value which is not desirable.</li>
</ul>

<h2>
<a id="author" class="anchor" href="#author" aria-hidden="true"><span class="octicon octicon-link"></span></a>Author</h2>

<p>The above project was done as part of the 'Data Analayst Nanodegree' by Roshan Shetty. Please contact me on <a href="mailto:rosshanabshetty@gmail.com">rosshanabshetty@gmail.com</a> for any doubts, queries or information.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset">NYC Subway Data Analysis</a> is maintained by <a href="https://github.com/Inquisitive-Geek">Inquisitive-Geek</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-67244594-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
