{"name":"NYC Subway Data Analysis","tagline":"Analysis and Regression modeling of NYC Subway dataset to check affect of rain on Subway ridership","body":"## Background\r\nIn this project, we look at the NYC Subway data and figure out if more people ride the subway when it is raining versus when it is not raining. We will wrangle the NYC subway data, use statistical methods and data visualization to draw an interesting conclusion about the subway dataset that we've analyzed.\r\n\r\n## Problems Encountered in the Map\r\nAfter initially downloading a small sample size of the Raleigh data and running it against a provisional data.py file, I noticed three main problems with the data, which I will discuss in the following order:\r\n* _Multiple streets for a node:_ A university like NCSU has multiple streets in it. But the street keys aren’t of the form “addr:street”. In such cases, the data is still cleaned for the streets but they are not added to an address dictionary value. Instead, the keys are kept as is.\r\n* _Relation nodes:_ There are some nodes who have element names as ‘Relation’. They are handled in a similar way as ways and nodes.\r\n* _Postal codes:_ There are a lot of postal codes which don’t pertain to Raleigh, NC. Some investigation is done around it to find out the root cause.\r\n\r\n### **Multiple streets for a node**\r\nThere are some tags which contain field values like “Street_1” and “Street_2”. They seem be the adjoining streets of a building and hence the attributes are kept as they are. \r\n\r\n### **Postal codes**\r\nRaleigh postal codes are in this range - 27587, 27601, 27605, 27608, 27609, 27612, 27613, 27614, 27615, 27616.[3] The database contains a lot of other values though. A lot of postal codes don’t refer to Raleigh, NC but the surrounding areas. \r\n\r\n```\r\n>>> x_post_code = db.data.aggregate([{\"$match\":{\"address.postcode\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$address.postcode\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":1}}])\r\n>>> list_post = list(x_post_code)\r\n>>> for i in list_post: print i['_id']\r\n```\r\nA subset of the results is shown here:\r\n27612-7156\r\n27612-3326\r\n27519-6205\r\n27511-5928\r\n\r\nIn the above list, many postal codes like 27519, 27511 are not in Raleigh. \r\nA query to find the list of cities confirms it too.\r\n\r\n```\r\n>>> x_city = db.data.aggregate([{\"$match\":{\"address.city\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$address.city\", \"count\":{\"$\r\n>>> x_city_l = list(x_city)\r\n>>> x_city_l\r\n[{u'count': 1, u'_id': u'cary'}, {u'count': 1, u'_id': u'Ra'}, {u'count': 1, u'_id': u'Apex'}, {u'count': 2, u'_id': u'W\r\nake Forest'}, {u'count': 2, u'_id': u'durham'}, {u'count': 2, u'_id': u'chapel Hill'}, {u'count': 2, u'_id': u'raleigh'}\r\n, {u'count': 108, u'_id': u'Morrisville'}, {u'count': 236, u'_id': u'Chapel Hill'}, {u'count': 279, u'_id': u'Carrboro'}\r\n, {u'count': 885, u'_id': u'Raleigh'}, {u'count': 1295, u'_id': u'Durham'}, {u'count': 1745, u'_id': u'Cary'}]\r\n```\r\nCities like Apex and Morrisville which are around Raleigh are also included in this extract. So the data gives info of Raleigh and its surrounding areas.\r\n\r\n## Data Overview\r\nThis section contains basic statistics about the dataset and the MongoDB queries used to gather them.\r\n                                                \r\n#### File sizes\r\nraleigh_north-carolina.osm……………………………………… 518045444 Bytes \r\n\r\n```\r\n# Finding out the file size\r\n>>> import os\r\n>>> statinfo = os.stat('new-york_new-york.osm')\r\n>>> print statinfo.st_size\r\n518045444\r\n```\r\n\r\nThe following are the counts of the various node types in the input file:\r\n```\r\n{'bounds': 1,\r\n 'member': 7683,\r\n 'nd': 2829895,\r\n 'node': 2564072,\r\n 'osm': 1,\r\n 'relation': 741,\r\n 'tag': 819970,\r\n 'way': 216498}\r\n```\r\n\r\nExploration of the data has been done to prevent issues while loading the data in MongoDB. The result is the following:\r\n```\r\n{'lower': 498201, 'lower_colon': 276537, 'other': 45231, 'problemchars': 1}\r\n```\r\nThe above categories have been formed by comparing the key value to various regular expressions written in the code leading to the above result.\r\n\r\n#### Number of documents\r\n```\r\n>>> db.data.find().count()\r\n2781311\r\n```\r\n\r\n#### Number of nodes\r\n```\r\n>>> db.data.find({\"type\":\"node\"}).count()\r\n2564072\r\n```\r\n\r\n#### Number of ways\r\n```\r\n>>> db.data.find({\"type\":\"way\"}).count()\r\n216498\r\n```\r\n\r\n#### Number of relations\r\n```\r\n>>> db.data.find({\"type\":\"relation\"}).count()\r\n741\r\n```\r\n\r\n#### Number of unique users                                                \r\n```\r\n>>> len(db.data.distinct(\"created.user\"))\r\n724\r\n```\r\n\r\n#### Top 1 contributing user\r\n```\r\n>>> x = db.data.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":1}])\r\n>>> print list(x)\r\n[{u'count': 2136690, u'_id': u'jumbanho'}]\r\n```\r\n\r\n#### Number of users appearing only once (having 1 post)\r\n```\r\n>>> x = db.data.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$group\":{\"_id\":\"$count\", \"num_users\r\n\":{\"$sum\":1}}}, {\"$sort\":{\"_id\":1}}, {\"$limit\":1}])\r\n>>> print list(x)\r\n[{u'num_users': 150, u'_id': 1}]\r\n```\r\n\r\n## Additional Ideas\r\n### **Contributor statistics and gamification suggestion**\r\nFew users contribute to the most data which suggests automated entry of some admin. Here are some statistics:\r\n* Top user contribution percentage (“jumbanho”) – 76.82%\r\n* Top user contribution percentage (“jumbanho”) – 76.82%\r\n\r\nIt is clear that the contribution of the top 10 users is too high as compared to the total number of users (724). If some incentives are given to the users to contribute more, it will help spur the data entry process and will also provide more quality to the data. \r\n\r\n### **Additional data exploration using MongoDB queries**\r\n#### Top 10 appearing amenities\r\n```\r\n>>> amenity_list = list(db.data.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}},{\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$s\r\num\":1}}},{\"$sort\":{\"count\":-1}},{\"$limit\":10}]))\r\n>>> amenity_list\r\n\r\n[{u'count': 1935, u'_id': u'parking'}, {u'count': 551, u'_id': u'place_of_worship'}, {u'count': 523, u'_id': u'bicycle_p\r\narking'}, {u'count': 499, u'_id': u'restaurant'}, {u'count': 254, u'_id': u'fast_food'}, {u'count': 227, u'_id': u'schoo\r\nl'}, {u'count': 205, u'_id': u'fuel'}, {u'count': 130, u'_id': u'bench'}, {u'count': 112, u'_id': u'bank'}, {u'count': 1\r\n08, u'_id': u'swimming_pool'}]          \r\n```\r\n\r\n#### Top 10 appearing shops                          \r\n```\r\n>>> shop_list = list(db.data.aggregate([{\"$match\":{\"shop\":{\"$exists\":1}}},{\"$group\":{\"_id\":\"$shop\",\"count\":{\"$sum\":1}}},\r\n{\"$sort\":{\"count\":-1}},{\"$limit\":10}]))\r\n>>>\r\n>>> shop_list\r\n[{u'count': 147, u'_id': u'convenience'}, {u'count': 117, u'_id': u'supermarket'}, {u'count': 94, u'_id': u'clothes'}, {\r\nu'count': 57, u'_id': u'car_repair'}, {u'count': 56, u'_id': u'hairdresser'}, {u'count': 52, u'_id': u'vacant'}, {u'coun\r\nt': 46, u'_id': u'mall'}, {u'count': 36, u'_id': u'department_store'}, {u'count': 36, u'_id': u'beauty'}, {u'count': 27,\r\n u'_id': u'jewelry'}]\r\n```\r\n\r\n#### Most popular supermarkets\r\n```\r\n>>> supermarket_list = list(db.data.aggregate([{\"$match\":{\"shop\":{\"$exists\":1},\"shop\":\"supermarket\"}},{\"$group\":{\"_id\":\"\r\n$name\",\"count\":{\"$sum\":1}}},{\"$sort\":{\"count\":-1}},{\"$limit\":2}]))\r\n>>> supermarket_list\r\n[{u'count': 22, u'_id': u'Food Lion'}, {u'count': 22, u'_id': u'Harris Teeter'}]\r\n```\r\n\r\n## Visualizations\r\n![Histogram of subway entry frequency v/s times](https://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset/blob/master/Images/Histogram.png?raw=true)\r\n\r\nhttps://github.com/Inquisitive-Geek/Analysing-NYC-Subway-Dataset/blob/master/Images/Histogram.png\r\n\r\n## Conclusion\r\nMore people ride the NYC subway when it rains as compared to when it does not. The low two-sided p-value of 0.0498 indicates that the null hypothesis that the mean subway number of hourly entries with rain is equal to that without rain is rejected. The linear model indicates that rain is an important variable in deciding the number of hourly entries. The positive coefficient value of 63.64 for variable ‘rain’ shows that subway ridership increases by 63.64 on average when it rains.\r\n\r\n## Reflection on Shortcomings\r\nThe shortcomings of the methods used are as follows:\r\n* The data is not captured for all the hourly intervals for each of the unit types indicating that the data is not complete. This causes a hindrance in building reliable models for our analysis.\r\n* The linear regression model has too many dummy variables being used. Ideally, the number of variables should be lesser in a dataset. The issue is that removing a few of the dummy variables caused a reduction in the R-squared value which is not desirable.\r\n\r\n## Author\r\nThe above project was done as part of the 'Data Analayst Nanodegree' by Roshan Shetty. Please contact me on rosshanabshetty@gmail.com for any doubts, queries or information.","google":"UA-67244594-1","note":"Don't delete this file! It's used internally to help with page regeneration."}